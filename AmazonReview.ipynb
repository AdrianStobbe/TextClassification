{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow Lite: Sentimental Analysis using Amazon review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Package import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Skipping tensorflow as it is not installed.\n",
      "WARNING: Skipping google-colab as it is not installed.\n"
     ]
    }
   ],
   "source": [
    "# Ignore  the warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('always')\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# data visualisation and manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "import seaborn as sns\n",
    "#configure\n",
    "# sets matplotlib to inline and displays graphs below the corressponding cell.\n",
    "%matplotlib inline  \n",
    "style.use('fivethirtyeight')\n",
    "sns.set(style='whitegrid',color_codes=True)\n",
    "\n",
    "!pip uninstall -q -y tensorflow google-colab grpcio\n",
    "!pip install -q tf-nightly\n",
    "#!pip install -q git+https://github.com/tensorflow/examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "assert tf.__version__.startswith('2')\n",
    "import sys\n",
    "sys.path.append('C:/Users/Adrian/Documents/examples')\n",
    "\n",
    "from tensorflow_examples.lite.model_customization.core.data_util.text_dataloader import TextClassifierDataLoader\n",
    "from tensorflow_examples.lite.model_customization.core.model_export_format import ModelExportFormat\n",
    "import tensorflow_examples.lite.model_customization.core.task.text_classifier as text_classifier\n",
    "\n",
    "from textdata_extension import from_panda\n",
    "TextClassifierDataLoader.from_panda = from_panda\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "rev_frame = pd.read_csv(\"Reviews.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>dll pa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1346976000</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1219017600</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>B000UA0QIQ</td>\n",
       "      <td>A395BORC6FGVXV</td>\n",
       "      <td>Karl</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1307923200</td>\n",
       "      <td>Cough Medicine</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A1UQRSCLF8GW1T</td>\n",
       "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1350777600</td>\n",
       "      <td>Great taffy</td>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id   ProductId          UserId                      ProfileName  \\\n",
       "0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
       "1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
       "2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
       "3   4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
       "4   5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
       "\n",
       "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "0                     1                       1      5  1303862400   \n",
       "1                     0                       0      1  1346976000   \n",
       "2                     1                       1      4  1219017600   \n",
       "3                     3                       3      2  1307923200   \n",
       "4                     0                       0      5  1350777600   \n",
       "\n",
       "                 Summary                                               Text  \n",
       "0  Good Quality Dog Food  I have bought several of the Vitality canned d...  \n",
       "1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...  \n",
       "2  \"Delight\" says it all  This is a confection that has been around a fe...  \n",
       "3         Cough Medicine  If you are looking for the secret ingredient i...  \n",
       "4            Great taffy  Great taffy at a great price.  There was a wid...  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df is the copy we process for sentimental analysis\n",
    "df=rev_frame.copy()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning and preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regard only 'Text' and 'Score' for analysis and rename them to 'review' and 'rating'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df[['Text','Score']]\n",
    "df['review']=df['Text']\n",
    "df['rating']=df['Score']\n",
    "df.drop(['Text','Score'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(568454, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  rating\n",
       "0  I have bought several of the Vitality canned d...       5\n",
       "1  Product arrived labeled as Jumbo Salted Peanut...       1\n",
       "2  This is a confection that has been around a fe...       4\n",
       "3  If you are looking for the secret ingredient i...       2\n",
       "4  Great taffy at a great price.  There was a wid...       5"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for null values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df['rating'].isnull().sum())\n",
    "df['review'].isnull().sum()  # no null values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove duplicates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove duplicates/ for every duplicate we will keep only one row of that type. \n",
    "df.drop_duplicates(subset=['rating','review'],keep='first',inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(393675, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  rating\n",
       "0  I have bought several of the Vitality canned d...       5\n",
       "1  Product arrived labeled as Jumbo Salted Peanut...       1\n",
       "2  This is a confection that has been around a fe...       4\n",
       "3  If you are looking for the secret ingredient i...       2\n",
       "4  Great taffy at a great price.  There was a wid...       5"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now check the shape. note that shape is reduced which shows that we did has duplicate rows.\n",
    "size = df.shape\n",
    "print(size)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mark_sentiment(rating):\n",
    "  if(rating<=3):\n",
    "    return 0\n",
    "  else:\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sentiment']=df['rating'].apply(mark_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  I have bought several of the Vitality canned d...          1\n",
       "1  Product arrived labeled as Jumbo Salted Peanut...          0\n",
       "2  This is a confection that has been around a fe...          1\n",
       "3  If you are looking for the secret ingredient i...          0\n",
       "4  Great taffy at a great price.  There was a wid...          1"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(['rating'],axis=1,inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(393675, 2)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Has not proven to be more successful!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup \n",
    "from nltk.stem import WordNetLemmatizer  # lammatizer from WordNet\n",
    "import re\n",
    "import nltk\n",
    "#nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords  #stopwords\n",
    "\n",
    "# function to clean and pre-process the text.\n",
    "def clean_reviews(review):  \n",
    "    \n",
    "    # 1. Removing html tags\n",
    "    review_text = BeautifulSoup(review,\"lxml\").get_text()\n",
    "    \n",
    "    # 2. Retaining only alphabets.\n",
    "    review_text = re.sub(\"[^a-zA-Z]\",\" \",review_text)\n",
    "    \n",
    "    # 3. Converting to lower case and splitting\n",
    "    word_tokens= review_text.lower().split()\n",
    "    \n",
    "    # 4. Remove stopwords\n",
    "    le=WordNetLemmatizer()\n",
    "    stop_words= set(stopwords.words(\"english\"))     \n",
    "    word_tokens= [le.lemmatize(w) for w in word_tokens if not w in stop_words]\n",
    "    \n",
    "    cleaned_review=\" \".join(word_tokens)\n",
    "    return cleaned_review\n",
    "\n",
    "## Ignore!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that pre processing all the reviews is taking way too much time and so we will take only 100K reviews. To balance the class we have taken equal instances of each sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_df=df.loc[df.sentiment==1,:][:25000]\n",
    "neg_df=df.loc[df.sentiment==0,:][:25000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>clean_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>I was expecting a bit better after reading oth...</td>\n",
       "      <td>0</td>\n",
       "      <td>expecting bit better reading review hot chocol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>I recently ordered these and was extremely dis...</td>\n",
       "      <td>0</td>\n",
       "      <td>recently ordered extremely disappointed proble...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Bought this at my local health food store. As ...</td>\n",
       "      <td>0</td>\n",
       "      <td>bought local health food store eating way bit ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>I'm just not sure a new cartridge is better th...</td>\n",
       "      <td>0</td>\n",
       "      <td>sure new cartridge better washed one maybe cat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Buyer beware. The coffee blend for Obsidian ap...</td>\n",
       "      <td>0</td>\n",
       "      <td>buyer beware coffee blend obsidian appears cha...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment  \\\n",
       "0  I was expecting a bit better after reading oth...          0   \n",
       "1  I recently ordered these and was extremely dis...          0   \n",
       "2  Bought this at my local health food store. As ...          0   \n",
       "3  I'm just not sure a new cartridge is better th...          0   \n",
       "4  Buyer beware. The coffee blend for Obsidian ap...          0   \n",
       "\n",
       "                                        clean_review  \n",
       "0  expecting bit better reading review hot chocol...  \n",
       "1  recently ordered extremely disappointed proble...  \n",
       "2  bought local health food store eating way bit ...  \n",
       "3  sure new cartridge better washed one maybe cat...  \n",
       "4  buyer beware coffee blend obsidian appears cha...  "
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#combining\n",
    "df=pd.concat([pos_df,neg_df],ignore_index=True)\n",
    "# shuffling rows\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['clean_review']=df['review'].apply(clean_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>clean_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>I was expecting a bit better after reading oth...</td>\n",
       "      <td>0</td>\n",
       "      <td>expecting bit better reading review hot chocol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>I recently ordered these and was extremely dis...</td>\n",
       "      <td>0</td>\n",
       "      <td>recently ordered extremely disappointed proble...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Bought this at my local health food store. As ...</td>\n",
       "      <td>0</td>\n",
       "      <td>bought local health food store eating way bit ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>I'm just not sure a new cartridge is better th...</td>\n",
       "      <td>0</td>\n",
       "      <td>sure new cartridge better washed one maybe cat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Buyer beware. The coffee blend for Obsidian ap...</td>\n",
       "      <td>0</td>\n",
       "      <td>buyer beware coffee blend obsidian appears cha...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment  \\\n",
       "0  I was expecting a bit better after reading oth...          0   \n",
       "1  I recently ordered these and was extremely dis...          0   \n",
       "2  Bought this at my local health food store. As ...          0   \n",
       "3  I'm just not sure a new cartridge is better th...          0   \n",
       "4  Buyer beware. The coffee blend for Obsidian ap...          0   \n",
       "\n",
       "                                        clean_review  \n",
       "0  expecting bit better reading review hot chocol...  \n",
       "1  recently ordered extremely disappointed proble...  \n",
       "2  bought local health food store eating way bit ...  \n",
       "3  sure new cartridge better washed one maybe cat...  \n",
       "4  buyer beware coffee blend obsidian appears cha...  "
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the end the cleaning process did not help to improve the accuracy of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following steps the Panda-object is loaded into an object that Tensorflow can process.\n",
    "We can choose to process the cleaned reviews or the raw reviews:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = TextClassifierDataLoader.from_panda(df,pd_label=['review','sentiment']).split(0.8) # The fraction describes the size of the training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at the data with it's classification and it's review:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: b'Item was in an envelope that was battered and very heavy, which was odd.  Upon opening I discovered why the envelope was so heavy, the chocolate was COMPLETELY melted.  They need to find a better way to ship this product, until then, I would STAY AWAY from ordering this item from THIS COMPANY!'\n",
      "1: b\"I've been using the MOCAFE Azteca for years.  Sweet and a bit of spice.  Mixes easily.  And you can get by with half the suggested amount.  Nothing warms you up faster on a cold, winter day.\"\n",
      "0: b\"I'm a flavored coffee fanatic, and was so excited to try this one.  What a major disappointment.  NO flavor at all.  Bleck.  Would NEVER buy or drink again, unless desperate and out of any other coffee!\"\n",
      "0: b\"The world's largest gummy bear is in Austin. It is 27 lbs and in Campus Candy. It's $149.99 and the store is awfully loud. Back to my original point, this post is lying. I have not bought this product though.\"\n",
      "1: b'I never buy flavored coffee.  I\\'m a cream, sugar and drizzle of caramel sauce type of coffee drinker.  When I read the reviews about this toffee flavored coffee I decided to try it with high hopes.<br /><br />As the coffee was brewing into the mug, I smelled a slight toffee scent.  It, and the coffee smelled good.  My hubs wanted a cup, just black.  I brought him his and after he drank some, while I was brewing mine, I asked him how he liked the flavor.  \"What flavor?\" he asked.  \"It tastes like coffee to me\" he said.  More questions to him and he said all he tasted was coffee, no flavor and the coffee was ok.<br /><br />Now for my cup.  I used about 1 inch of milk, one spoon of sugar and the Keurig on medium brewing setting.  The same faint scent of toffee was there along with the coffee.  I took my first sip and hardly tasted any toffee flavor.  I looked at the k-cup and it said \\'toffee\\' on it so it was the correct k-cups that were sent.  It is such a mild, almost non-existent flavor that I wouldn\\'t hesitate to serve this to those who don\\'t like flavored coffee, I\\'m sure they would like it.  I\\'m disappointed in the weak flavor of toffee but the coffee itself is good tasting so it\\'s not a waste.  I\\'m used to extra-bold, dark/french roasts so this is a much lighter roast for me.  All in all I like it.'\n",
      "1: b'This is the most delicious of all the packaged soups I have tried.  Be sure to let the rice noodles set a while so they thicken sufficiently.  I use a fork and spoon  to twirl the noodles.'\n",
      "0: b\"Okay so for the price, this is to be expected, after all, it's organic. I was in a pinch for vanilla extract (REAL Vanilla Extract) and I bought here on Amazon. I know for the same price, this cost just as much at my local Whole Foods, but I bought here and was quite pleased with the product. It's a real high quality extract and using it in my baked goods and some other dishes, I could tell the difference in taste. I use a lot of vanilla extract so for me the only real downside is/was they don't make it bigger. Perhaps I will have to buy this in bulk.\"\n",
      "0: b'These are what the picture shows however I wish the ingredients would have been labeled before I purchased (food allergy/preservative sensitive).  Also, some of the packets were punctured which did cause some issues with the entire bag being a mess.  We ended up throwing out the entire bag of the salt and pepper (separate purchase).'\n",
      "0: b\"The candy was very good but I was scared to eat them because the bag had a hole in it when I opened up the box. I was very unhappy about that and almost didn't use them for my baby shower. But after a few people tried them I decided to use them and everyone loved them and finished the two big bags.\"\n",
      "0: b'I was in rush to grab something quick from the grocery on my way to work. I usually pack my lunch but somedays I simply don\\'t have a time for it. When I first opened up the box, they were individually packed which was a plus. However, the taste? EHhh. It was so stale. Basically not palatable at all. And more to that, as I was reading the nutrition label, the second most thing that was added as its ingredients? \"high fructose corn syrup\". Another big thing was partially hydrogenated soybean oils. Those two must be regulated and possibly BANNED. Of course, manufacturers still use those because using partially hydrogenated oil is much cheaper than using other kinds of oils that are still avaiable out there today. Those of you who think it\\'s not big of a deal, ok. It is your choice to put crap in your mouth to damage your body in long run, so I don\\'t have any control over that. Quakers obviously needs to utilize better ingredients.'\n"
     ]
    }
   ],
   "source": [
    "for text, label in train_data.dataset.take(10):\n",
    "  print (\"%s: %s\"%(train_data.index_to_label[label.numpy()], text.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Retraining the models...\n",
      "Train for 1000 steps, validate for 125 steps\n",
      "Epoch 1/3\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5898 - accuracy: 0.6926 - val_loss: 0.4439 - val_accuracy: 0.8217\n",
      "Epoch 2/3\n",
      "1000/1000 [==============================] - 24s 24ms/step - loss: 0.3984 - accuracy: 0.8359 - val_loss: 0.3827 - val_accuracy: 0.83533 - - ETA: 17s - loss: 0.4472 - accuracy: 0. -  - ETA: 14s \n",
      "Epoch 3/3\n",
      "1000/1000 [==============================] - 24s 24ms/step - loss: 0.3430 - accuracy: 0.8636 - val_loss: 0.3580 - val_accuracy: 0.84874s - loss: 0.3443 - accuracy: 0. - ETA:  - ETA: 2s - loss: 0.3436 - accuracy:  - ETA: 2s - loss: 0.3436 -  - ETA: 0s - loss: 0.3\n"
     ]
    }
   ],
   "source": [
    "model = text_classifier.create(train_data, epochs=3,num_words=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While trying out different parameters we found out that the model gives good results with the standard parameters. Increasing the word vocabulary or wordvector dimension lead to overfitting (training loss much smaller than validation loss)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can have a look at the specifics of the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_11 (Embedding)     (None, 256, 16)           160048    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_11  (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 2)                 34        \n",
      "=================================================================\n",
      "Total params: 160,354\n",
      "Trainable params: 160,354\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After training we should test our model on some unseen test data to evaluate our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 6s 21ms/step - loss: 0.3570 - accuracy: 0.8492\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we can export the model to use it in the App using TensorFlow Lite :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Export to tflite model amazon_review_classifier_nclean50k.tflite, saved labels in text_label_nc50k.txt.\n",
      "INFO:tensorflow:  Saved vocabulary in vocab_nc50k.txt.\n"
     ]
    }
   ],
   "source": [
    "model.export('amazon_review_classifier_nclean50k.tflite', 'text_label_nc50k.txt', 'vocab_nc50k.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Lite model accuracy = 0.8590\n"
     ]
    }
   ],
   "source": [
    "# Read TensorFlow Lite model from TensorFlow Lite file.\n",
    "with tf.io.gfile.GFile('amazon_review_classifier_nclean50k.tflite', 'rb') as f:\n",
    "  model_content = f.read()\n",
    "\n",
    "# Read label names from label file.\n",
    "with tf.io.gfile.GFile('text_label_nc50k.txt', 'r') as f:\n",
    "  label_names = f.read().split('\\n')\n",
    "\n",
    "# Initialze TensorFlow Lite inpterpreter.\n",
    "interpreter = tf.lite.Interpreter(model_content=model_content)\n",
    "interpreter.allocate_tensors()\n",
    "input_index = interpreter.get_input_details()[0]['index']\n",
    "output = interpreter.tensor(interpreter.get_output_details()[0][\"index\"])\n",
    "\n",
    "# Run predictions on each test data and calculate accuracy.\n",
    "accurate_count = 0\n",
    "for i, (text, label) in enumerate(model.test_data.dataset):\n",
    "    # Pre-processing should remain the same.\n",
    "    text, label = model.preprocess(text, label)\n",
    "    # Add batch dimension and convert to float32 to match with the model's input\n",
    "    # data format.\n",
    "    text = tf.expand_dims(text, 0).numpy()\n",
    "    text = tf.cast(text, tf.float32)\n",
    "\n",
    "    # Run inference.\n",
    "    interpreter.set_tensor(input_index, text)\n",
    "    interpreter.invoke()\n",
    "\n",
    "    # Post-processing: remove batch dimension and find the label with highest\n",
    "    # probability.\n",
    "    predict_label = np.argmax(output()[0])\n",
    "    # Get label name with label index.\n",
    "    predict_label_name = label_names[predict_label]\n",
    "    \n",
    "    accurate_count += (predict_label == label.numpy())\n",
    "\n",
    "accuracy = accurate_count * 1.0 / model.test_data.size\n",
    "print('TensorFlow Lite model accuracy = %.4f' % accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
